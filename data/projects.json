[
  {
    "id": "ecommerce-platform",
    "title": "Shyply",
    "blurb": "Built a full-stack e-commerce platform using Node.js, TypeScript, and NextAuth.js with real-time inventory management and payment processing.",
    "descriptionMD": "## E-Commerce Platform\n\nA comprehensive e-commerce solution built from the ground up with modern web technologies. Features include:\n\n- **Frontend**: TypeScript\n- **Backend**: Node.js with Express, RESTful API design\n- **Database**: MongoDB with Mongoose ODM\n- **Payment**: Stripe integration for secure transactions\n- **Authentication**: JWT-based auth with refresh tokens\n- **Real-time**: WebSocket integration for live inventory updates\n\n### Key Features\n- User authentication and authorization\n- Product catalog with search and filtering\n- Shopping cart and wishlist functionality\n- Order management and tracking\n- Admin dashboard for inventory management\n- Responsive design for all devices",
    "tech": ["Next.js", "TypeScript", "Tailwind CSS", "NextAuth.js", "Stripe", "Cloudinary"],
    "image": "/images/ecommerce-project.jpg",
    "liveUrl": "https://ecommerce-demo.com",
    "githubUrl": "https://github.com/carlpaolino/Shyply"
  },
  {
    "id": "activity-planner",
    "title": "QuickMap",
    "blurb": "Developed an intelligent activity planner using Google Maps Places API and SeatGeek API, featuring suggested activities and events based on user location and preferences.",
    "descriptionMD": "## Activity Planner\n\nAn intelligent activity planner using Google Maps Places API and SeatGeek API, featuring suggested activities and events based on user location and preferences.\n\n### Architecture\n- **Frontend**: React with TypeScript and Material-UI\n- **Backend**: Node.js with Express\n- **AI Integration**: OpenAI GPT-4 API with custom fine-tuning\n- **Database**: MongoDB\n- **Vector Search**: Pinecone for semantic document retrieval\n\n### Key Features\n- Real-time location-based activity directory\n- Activity Categorization(fun, hikes, food, etc.)\n- Detailed activity planning\n- Modern, responsive UI\n- Future IOS app integration ready",
    "tech": ["Next.js", "Python", "FastAPI", "OpenAI", "PostgreSQL", "Pinecone"],
    "image": "/images/QuickMapImage.png",
    "liveUrl": "https://ai-assistant-demo.com",
    "githubUrl": "https://github.com/carlpaolino/Quick-Map"
  },
  {
    "id": "3d_web_game",
    "title": "3D Web Broswer Game",
    "blurb": "Created a mimic of Gang Beasts using Three.js and React.",
    "descriptionMD": "## 3D Web Broswer Game\n\nA 3d web broswer game built from scratch by myself and a team from Georgia Tech.\n\n### Technical Stack\n- **Frontend**: Three.js, HTML, CSS\n- **Backend**: NestJS with TypeORM\n- **Real-time**: Socket.io for live collaboration\n\n### Core Features\n- **Project Management**: Create and organize projects with custom workflows\n- **Team Collaboration**: Real-time updates and notifications\n- **Task Tracking**: Kanban boards, Gantt charts, and calendar views",
    "tech": ["Three.js", "NestJS", "PostgreSQL", "HTML", "Socket.io"],
    "image": "/images/webdevimage.png",
    "liveUrl": "https://taskmanager-demo.com",
    "githubUrl": "https://github.com/noahzanecook/haymakers"
  },
  {
    "id": "machine-learning-pipeline",
    "title": "ML Data Processing Pipeline",
    "blurb": "Built a scalable machine learning pipeline for processing large datasets with automated model training and deployment capabilities.",
    "descriptionMD": "## Machine Learning Data Processing Pipeline\n\nA robust, scalable pipeline for processing large datasets and training machine learning models in production environments.\n\n### Architecture Overview\n- **Data Ingestion**: Apache Kafka for streaming data\n- **Processing**: Apache Spark with PySpark for distributed computing\n- **ML Framework**: TensorFlow and Scikit-learn\n- **Orchestration**: Apache Airflow for workflow management\n- **Monitoring**: MLflow for experiment tracking\n- **Deployment**: Kubernetes with Docker containers\n\n### Key Components\n\n#### Data Processing\n- Real-time data ingestion from multiple sources\n- Data validation and quality checks\n- Feature engineering and transformation pipelines\n- Automated data cleaning and preprocessing\n\n#### Model Training\n- Automated hyperparameter tuning with Optuna\n- Distributed training across multiple GPUs\n- A/B testing framework for model comparison\n- Automated model validation and testing\n\n#### Deployment & Monitoring\n- Continuous integration for model updates\n- Real-time model performance monitoring\n- Automated rollback capabilities\n- Comprehensive logging and alerting\n\n### Results\n- Reduced model training time by 70% through parallelization\n- Achieved 94% accuracy on production datasets\n- Processed over 1TB of data daily with 99.5% reliability",
    "tech": ["Python", "TensorFlow", "Apache Spark", "Kafka", "Kubernetes", "MLflow"],
    "image": "/images/ml-pipeline-project.jpg",
    "githubUrl": "https://github.com/carlpaolino/ml-pipeline"
  }
] 